{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Advisor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Import Trip Advisor data\n",
    "2. Tokenize the data (create a word index that represents words as numbers)\n",
    "3. Use an oov token to include words not seen before\n",
    "4. Pad the sentences to have similar length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Variables\n",
    "vocab_size = 10000\n",
    "trunc_type =\"post\"\n",
    "padding_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8270</td>\n",
       "      <td>okay steal, unfortunate items cosmetics taken ...</td>\n",
       "      <td>1</td>\n",
       "      <td>443</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>excellent value super value hotel right kurfue...</td>\n",
       "      <td>5</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "      <td>1689</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6025</td>\n",
       "      <td>worst vacation, fiance stayed 7 nights bbp jun...</td>\n",
       "      <td>1</td>\n",
       "      <td>3533</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2802</td>\n",
       "      <td>beware, not room went paradisus 6 days wedding...</td>\n",
       "      <td>1</td>\n",
       "      <td>411</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review  Rating  \\\n",
       "0        8270  okay steal, unfortunate items cosmetics taken ...       1   \n",
       "1       14380  excellent value super value hotel right kurfue...       5   \n",
       "2           1  ok nothing special charge diamond member hilto...       2   \n",
       "3        6025  worst vacation, fiance stayed 7 nights bbp jun...       1   \n",
       "4        2802  beware, not room went paradisus 6 days wedding...       1   \n",
       "\n",
       "   Length  weight  \n",
       "0     443       5  \n",
       "1     337       1  \n",
       "2    1689       4  \n",
       "3    3533       5  \n",
       "4     411       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('to_model.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"experience melia caribe girlfriend recently went melia caribe sept 9th 14th, reading numerous reviews watching weather channel prior leaving say bit nervous upcoming trip, hopefully review answer questions headed resort helpful, try cover informed be.first booked trip hotel website solmelia.com, sol melia resorts actually offers low-price online guarantee booking easy not problem, thing need aware booking hotel website not charge credit card make reservation charge card check hotel, based reviews tripadvisor.com decided royal service master suite.we flew atlanta dominican republic delta airlines, offer flights twice week stay typically days.you arrive dominican republic airport walk plane terminal, wait line enter terminal picture flight wall case want buy, clear photo op open wallet purse pay 10 person tourist entry card, completely meaningless not visa dr poor country charge dollars just in.once bags swarmed baggage handlers eager grab bags awaiting taxi, word advice carry bags, short walk taxi areas n't know happen bags let, taxis lined outside terminal, n't accept standard price taxi drivers bargain, resort 20 typically start 25, drive melia caribe boring n't bother pulling camera, arrived showed baggage handler reservation took royal service lounge reception area, staff royal service lounge nice, present drinks come immediately checked room, lounge introduced personal butler takes care, butler pablo great duration stay, butler drive room unload baggage work safe leave enjoy vacation, looking great butler ask pablo.our room nice bed n't comfortable world, not supportive actually slightly bowed middle, bathroom situation pretty wierd shower pretty view entire room n't comfortable bathroom habits wife/girlfriend/family member time trip, jacuzzi master suite nice butler filled ready time like, pablo care jacuzzi tub twice stay great, recommend bringing citronella candle week bug spray mosquitos room night n't, maids clean room day restock fridge, room service menu limited, sandwiches small pizzas waters/sodas, n't expect full-blown menu.the royal service villas right gabi restaurant royal service pool, pool great surprisingly clean, actually swam pool goggles pretty shocked clean, pool great plenty private cabanas need shade sun, girlfriend spent time beach awesome, white sand beaches clear turquoise water really did n't better, fantastic weather week weather channel forecasted rain week, beach drink/wait staff n't great towels drinks leave, beach activities plentyful costs money so-called free activities, went snorkeling sharks great afternoon activity, stick beach looking relaxing time family friends.up point really not complaints resort probably wondering gave melia caribe stars, biggest complaint food, restaurants really sad terms selection quality food variation menus, gabi restaurant supposed best resort pretty sad, service good food just n't great, n't expect gourmet meals, restaurant thought ok mexican food restaurant la hacienda, drinks pretty bland/weak not alcohol content, wine not great, actually felt bad lot waiters actually ask make dining experience better quality food just sub-par.so overall experience girlfriend melia caribe tropical good, relaxing vacation resort beautiful, prepared not eat just fine, hope review helped plan visit enjoy trip,  \", 'good comfortable not great stayed comfort suites june 12-16th, hotel bit core downtown area convenient monorail space needle experience music project/science fiction museum, easily spend day space needle emp/sfm right 15 covers emp science fiction museum price, took monorail downtown shopping walked pikes market, say surprised 4 round trip/adult price tag approx, 1 mile monorail ride hotel room not suite, standard double-bed room, did small fridge microwave, bathroom spacious clean plenty towels, water pressure shower great, beds quite comfortable not soft not firm.the heat/ac unit really odd looked brand new programmable settings unusual sound like raging tornado just outside window, kept awake night light sleeper not restaurant site quite nearby terrific mediterranean restaurant west hotel plus grocery store corner, evening simply sick eating restaurants not terribly hungry went grocery purchased ready-made sandwiches sodas ate outside hotel courtyard back.there complimentary continental breakfast lobby consisted cold cereals oatmeal sausage patties make-them-yourself waffles fruit breakfast danish coffee juice hot tea, ok crowded difficult place sit allow food room desire, free coffee lobby day.the personnel worked kind blase not overly friendly not rude, checked early saturday morning 5 gal desk not receipt stay, printed let look make sure showed charges correctly 0 balance not let copy kept saying needed website, not understand procedure tried explain definitely common practice checking receive receipt spoke broken english, minutes dd not time argue needed leave airport right away, customer service fax copy keeping eye credit card statement online make sure nothing charged card.overall average hotel nothing write home, clean date reasonably priced compared seattle paid 145/night tues weds, 162/night thurs friday, inside parking free nice bonus hotels checked charged 25/day park,  ', \"highly recommended superior room stayed globus 3 nights arrived s.m.n, eventually figured road actually small narrow lane said reception floor accessed stairs not ideal able bodied not greatest challenge world.bright friendly helpful staff reception cleaners breakfast guy clean tidy communal areas.we booked superior room hotel website worked 10 euro standard room night difference worth, rm 309 no view speak laptop free wifi comp, non alcoholic drinks minibar plenty space, bathroom good well.location great small gelateria right outside door small corner shops uk phrase, nearby market road duomo maybe 10 mins walk away.make sure check restaurants market zaza particularly does n't greatest location sit eat good food atmosphereall high highly recommended taking short break florence,  \", \"good basic hotel looking hotel stay night began cruise, wanted clean safe hotel provided free shuttle service airport port miami did n't cost arm leg, hotel delivered.we arrived airport called hotel told shuttle way, arrived 5 minutes later, arrival asked ship taking day placed shuttle list ship, desk staff courteous professional.our room fine, clean bed comfortable room microwave fridge, shower nice water pressure bathroom n't small, read reviews indicated noise nearby airport excessive, did not experience, opened window morning checked heard planes flying 10 minutes window closed did n't hear airport noise.the continental breakfast typical hotel breakfast cereal hard-boiled eggs bagels pastries milk juice coffee make-your-own waffle station, busy n't tables breakfast room eat, shuttle arrived exactly 11:30 scheduled took cruise ship 15 minutes easy be.this hotel gives exactly advertises not bit, no hot tub no fitness center no work station 1 nearby restaurant bennigan, pretty isolated rest miami unless rent cab rental car, knew going, 145/night little high basic kind hotel hotel, probably going rate hotels miami january hotels city amenities higher nightly rates, hotel said did, said doing just things doing, stay needed 1-night stay free shuttles to/from airport port, overall satisfied stay,  \", \"not good place carribe hilton business conference jan 22-27 2006 not good experience, arrived 5:30 sunday desk gave standard check card saying room ready 4 earlier told not ready hour, finally got room 7:30 no explanation no upgrade, room 7th floor tower, large quite dated, tv small set cabinet wall look sideways bed sat easy chair way room, no light chair n't sit read evening, bathroom fixtures sort dirty not toilet tended flush odd hours quite loudly, view lagoon just small lake construction going, phones room faulty not hear fail middle forcing realized party n't heard awhile, took 2 days replace phones brought problem, charge 1.25 outgoing, went desk ask 2 charges resulted hotel phone failing mid-call having recall phones worked correctly n't recall incur extra expenses, desk woman flat refused arguing calls charges charges, eventually called got phones worked head communications calls messages agreed deduct unnecessary charges, group business meeting lights did n't work correctly days trying hotel people fix group organizer gave, overall place nice opened 1949 n't line people rude unhelpful,  \"]\n",
      "[4, 1, 4, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "sentences = list(df['Review'])\n",
    "labels = list(df['Rating'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, random_state=0)\n",
    "\n",
    "print(X_train[:5])\n",
    "print(y_train[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words (bag of words) with an oov token\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  79 1108  788 1139  614   52 1108  788 2632 2061 2823  486 1081   76\n",
      " 1258  514 2307  896  531   78   74 1970 7846   51 2687  377 1302  797\n",
      " 1778   25   49  142 2065  883 3181 2327   65   51    2  362    1 1117\n",
      " 2488 1108  363  246  916  639   66 1132 2927  320  183    4   90  134\n",
      "  103  997  320    2  362    4  289  624  331   67  301  289  331   55\n",
      "    2  580   76  773 1117  361  635   17 3277  206  120 2244 5775  346\n",
      " 1094 5176 3193  393 1484  406  105   10 2592   82  623  704  346 1094\n",
      "   99   40 1492 1951  198  322 1522 1951 1249  359  422  613   62  520\n",
      "  712 2587 9356  135 3592 4250  148   85  243  441 2140  331  579    1\n",
      "    4 3480 1060  308  485  289  636   12  169 3148  447    1 2073    1\n",
      " 2116 1740  447 4794  286 1022  746 1271  447  252   40  286  342    5\n",
      "  124 1238  447  267 1116 3031  151 1951    5 1759  272   66  286 1724\n",
      " 1403   25  219 2592  381  517  716 1108  788 1794    5  630 4298 1883\n",
      "   95  876 2073    1  301   97  635   17  312  146   37    8  635   17\n",
      "  312   14 2043  121  178  650  233    3  312 5602 1106 3274  810  350\n",
      " 3274 6476    6 4228   10 3274  716    3 8781 2073  158  224  258  277\n",
      "  116  140    6 3274  187 6476  779    3   14   44    5   69  400    4\n",
      " 9401  246  833    1  509   45 1133  119 7401   92  119   57  435    3\n",
      "    5   69   45 6244  254 1139  200  747   19   51 1026 3277  206   14\n",
      " 3274 1126  304   19   26 6476  350 1026  451  406   10    6   68 2750\n",
      "    1 4144  105 1290 1462 1783    3   15    5 1378   24    3   21 4543\n",
      "  528    3   17  571  563 2401   33 4096 2058 3246    5  193 4547 2904\n",
      "  571   28  635   17 1989   61 3571   46  635   17   30   30    6 2180\n",
      "   24  246 4204   30    1  119 2107   24   30    6  236  657 4389  103\n",
      " 1090  483 1139  253   19   18  572  552  512  766  712 3524   43   29\n",
      "    9    5   54  133  514  105  514 2307    1  923  105   18  205  198\n",
      "    8    5    6  175  121  258   18  401 9146 1067   96  682  180   72\n",
      "  401   52 1268 2086    6  496 1409 1874   18  140  461   19  200  310\n",
      "  723  408   29    4  652   25  235 3869  245 1108  788  658  972  534\n",
      "   22   50   29 2121 1478  500  241   22    1 2547 3571   46  871   48\n",
      "   25  119 2121   17    7   22   12    5    6    5  193 1830  637   46\n",
      "  179  113  728   22   46  269 4466  121  119 2200 2392    4 1161 5446\n",
      "  349    4    6  246  215   84  107 1377  246  187   67  538   79   54\n",
      "  241   22   12 3422 1769  682  100   79 1139 1108  788  685    7  461\n",
      "  116   25   58  644    4  126   12  145  648  377  732  669  194  277\n",
      "   51    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "(4610, 563)\n"
     ]
    }
   ],
   "source": [
    "sequences_training = tokenizer.texts_to_sequences(X_train)\n",
    "max_length = int(np.median([len(x) for x in X_train]))\n",
    "padded_training = pad_sequences(\n",
    "    sequences_training, \n",
    "    padding=padding_type, \n",
    "    truncating=trunc_type,\n",
    "    maxlen=max_length\n",
    ")\n",
    "\n",
    "print(padded_training[0])\n",
    "print(padded_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8489  737  311  347  503  116  546  116   60  117  255    1   18 1619\n",
      " 3823  851 3996   65  511  242 4362   76 1970  179    1   60  117  190\n",
      " 6176    1   60  117 1967 1174 5870  619   51   65 1130 1033   32  732\n",
      " 8937  377  111 4709  704   25  105  162 2253   95   42 1381    8    9\n",
      "    4   62 3088 3975  185    4  952 1061  703    3 4255  172  323  551\n",
      "  217  739  253  172  382 3834 1133  551  491   17 1448 3059   22   50\n",
      "  255   10  511   48   22   33  686  223    1  211 5845   35  885 2999\n",
      " 1930 2136 1336    7   77  135 3300 1692 2034  126   77 1451  623   60\n",
      " 1599    4  108    1  596 1589  800 1856    1 1807  107 1890 2749 1881\n",
      " 3175  138 2205 2057  920 1910 1380  174    1  181  583   17 2162  699\n",
      "    9   47  641  198   41    8   38   32  248  105   17 2592  582 1381\n",
      "  616  687  571  579  177  412  968 1180 5480  291  644  378  164   19\n",
      "  450  582   41  121    7   17    4 6340 1161 1815 1404  497    1    4\n",
      " 1183   96   13   24 1906 2203 1120  742    2   25    3 1455  426   39\n",
      "   59    3 5595 1978 1799  154 3348  418  263   30  572    1   58 8259\n",
      "  512  560 3524  851   43  755  372  113   39 8655  755  255  559  222\n",
      "  372   38   85 1215 2348  255 1469 1067  160  239  243 1036  210  241\n",
      "  372  111 5509    4  190  271   51  199   35    1  469   17  593  215\n",
      " 7929   25    1  127   10   71   25    1  346  611 1613  494    7  336\n",
      "   51  831    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "(1537, 563)\n"
     ]
    }
   ],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "padded_test = pad_sequences(\n",
    "    sequences_test, \n",
    "    padding=padding_type, \n",
    "    truncating=trunc_type,\n",
    "    maxlen=max_length\n",
    ")\n",
    "\n",
    "print(padded_test[0])\n",
    "print(padded_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this block to get it to work with TensorFlow 2.x\n",
    "import numpy as np\n",
    "padded_training = np.array(padded_training)\n",
    "y_train = np.array(y_train)\n",
    "padded_test = np.array(padded_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 563, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 160,742\n",
      "Trainable params: 160,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "145/145 - 0s - loss: 1.6762 - accuracy: 0.2946 - val_loss: 1.5730 - val_accuracy: 0.3188\n",
      "Epoch 2/50\n",
      "145/145 - 0s - loss: 1.5807 - accuracy: 0.3078 - val_loss: 1.5456 - val_accuracy: 0.3188\n",
      "Epoch 3/50\n",
      "145/145 - 0s - loss: 1.5676 - accuracy: 0.3004 - val_loss: 1.5354 - val_accuracy: 0.3188\n",
      "Epoch 4/50\n",
      "145/145 - 0s - loss: 1.5542 - accuracy: 0.2950 - val_loss: 1.5278 - val_accuracy: 0.3201\n",
      "Epoch 5/50\n",
      "145/145 - 0s - loss: 1.5357 - accuracy: 0.3100 - val_loss: 1.4933 - val_accuracy: 0.3240\n",
      "Epoch 6/50\n",
      "145/145 - 0s - loss: 1.4747 - accuracy: 0.3356 - val_loss: 1.4237 - val_accuracy: 0.3494\n",
      "Epoch 7/50\n",
      "145/145 - 0s - loss: 1.3844 - accuracy: 0.3672 - val_loss: 1.3344 - val_accuracy: 0.3936\n",
      "Epoch 8/50\n",
      "145/145 - 0s - loss: 1.2870 - accuracy: 0.4093 - val_loss: 1.2503 - val_accuracy: 0.4105\n",
      "Epoch 9/50\n",
      "145/145 - 0s - loss: 1.2091 - accuracy: 0.4282 - val_loss: 1.1950 - val_accuracy: 0.4392\n",
      "Epoch 10/50\n",
      "145/145 - 0s - loss: 1.1564 - accuracy: 0.4562 - val_loss: 1.1662 - val_accuracy: 0.4502\n",
      "Epoch 11/50\n",
      "145/145 - 0s - loss: 1.1201 - accuracy: 0.4542 - val_loss: 1.1399 - val_accuracy: 0.4717\n",
      "Epoch 12/50\n",
      "145/145 - 0s - loss: 1.0943 - accuracy: 0.4716 - val_loss: 1.1163 - val_accuracy: 0.4684\n",
      "Epoch 13/50\n",
      "145/145 - 0s - loss: 1.0641 - accuracy: 0.4866 - val_loss: 1.1006 - val_accuracy: 0.4606\n",
      "Epoch 14/50\n",
      "145/145 - 0s - loss: 1.0417 - accuracy: 0.4918 - val_loss: 1.0877 - val_accuracy: 0.5159\n",
      "Epoch 15/50\n",
      "145/145 - 0s - loss: 1.0142 - accuracy: 0.5163 - val_loss: 1.0755 - val_accuracy: 0.5029\n",
      "Epoch 16/50\n",
      "145/145 - 0s - loss: 0.9907 - accuracy: 0.5334 - val_loss: 1.0651 - val_accuracy: 0.5179\n",
      "Epoch 17/50\n",
      "145/145 - 0s - loss: 0.9696 - accuracy: 0.5282 - val_loss: 1.0533 - val_accuracy: 0.5374\n",
      "Epoch 18/50\n",
      "145/145 - 0s - loss: 0.9507 - accuracy: 0.5529 - val_loss: 1.0478 - val_accuracy: 0.5322\n",
      "Epoch 19/50\n",
      "145/145 - 0s - loss: 0.9278 - accuracy: 0.5800 - val_loss: 1.0430 - val_accuracy: 0.5322\n",
      "Epoch 20/50\n",
      "145/145 - 0s - loss: 0.9059 - accuracy: 0.5898 - val_loss: 1.0256 - val_accuracy: 0.5420\n",
      "Epoch 21/50\n",
      "145/145 - 0s - loss: 0.8869 - accuracy: 0.6061 - val_loss: 1.0189 - val_accuracy: 0.5550\n",
      "Epoch 22/50\n",
      "145/145 - 0s - loss: 0.8533 - accuracy: 0.6267 - val_loss: 1.0118 - val_accuracy: 0.5582\n",
      "Epoch 23/50\n",
      "145/145 - 0s - loss: 0.8362 - accuracy: 0.6377 - val_loss: 1.0087 - val_accuracy: 0.5615\n",
      "Epoch 24/50\n",
      "145/145 - 1s - loss: 0.8266 - accuracy: 0.6412 - val_loss: 0.9983 - val_accuracy: 0.5634\n",
      "Epoch 25/50\n",
      "145/145 - 1s - loss: 0.8061 - accuracy: 0.6488 - val_loss: 1.0046 - val_accuracy: 0.5628\n",
      "Epoch 26/50\n",
      "145/145 - 0s - loss: 0.7869 - accuracy: 0.6592 - val_loss: 0.9957 - val_accuracy: 0.5693\n",
      "Epoch 27/50\n",
      "145/145 - 0s - loss: 0.7573 - accuracy: 0.6783 - val_loss: 0.9908 - val_accuracy: 0.5699\n",
      "Epoch 28/50\n",
      "145/145 - 0s - loss: 0.7356 - accuracy: 0.6863 - val_loss: 1.0020 - val_accuracy: 0.5654\n",
      "Epoch 29/50\n",
      "145/145 - 0s - loss: 0.7144 - accuracy: 0.7013 - val_loss: 0.9920 - val_accuracy: 0.5797\n",
      "Epoch 30/50\n",
      "145/145 - 0s - loss: 0.6961 - accuracy: 0.7219 - val_loss: 0.9962 - val_accuracy: 0.5777\n",
      "Epoch 31/50\n",
      "145/145 - 0s - loss: 0.6839 - accuracy: 0.7174 - val_loss: 0.9963 - val_accuracy: 0.5810\n",
      "Epoch 32/50\n",
      "145/145 - 0s - loss: 0.6656 - accuracy: 0.7286 - val_loss: 1.0000 - val_accuracy: 0.5804\n",
      "Epoch 33/50\n",
      "145/145 - 0s - loss: 0.6344 - accuracy: 0.7518 - val_loss: 1.0044 - val_accuracy: 0.5849\n",
      "Epoch 34/50\n",
      "145/145 - 0s - loss: 0.6301 - accuracy: 0.7501 - val_loss: 1.0075 - val_accuracy: 0.5823\n",
      "Epoch 35/50\n",
      "145/145 - 0s - loss: 0.6086 - accuracy: 0.7620 - val_loss: 1.0199 - val_accuracy: 0.5888\n",
      "Epoch 36/50\n",
      "145/145 - 0s - loss: 0.5907 - accuracy: 0.7685 - val_loss: 1.0249 - val_accuracy: 0.5862\n",
      "Epoch 37/50\n",
      "145/145 - 0s - loss: 0.5708 - accuracy: 0.7779 - val_loss: 1.0274 - val_accuracy: 0.5823\n",
      "Epoch 38/50\n",
      "145/145 - 0s - loss: 0.5632 - accuracy: 0.7813 - val_loss: 1.0636 - val_accuracy: 0.5921\n",
      "Epoch 39/50\n",
      "145/145 - 0s - loss: 0.5414 - accuracy: 0.7976 - val_loss: 1.0513 - val_accuracy: 0.5836\n",
      "Epoch 40/50\n",
      "145/145 - 0s - loss: 0.5286 - accuracy: 0.7985 - val_loss: 1.0545 - val_accuracy: 0.5908\n",
      "Epoch 41/50\n",
      "145/145 - 0s - loss: 0.5135 - accuracy: 0.8100 - val_loss: 1.0628 - val_accuracy: 0.5869\n",
      "Epoch 42/50\n",
      "145/145 - 0s - loss: 0.4984 - accuracy: 0.8167 - val_loss: 1.0760 - val_accuracy: 0.5908\n",
      "Epoch 43/50\n",
      "145/145 - 0s - loss: 0.4856 - accuracy: 0.8169 - val_loss: 1.1050 - val_accuracy: 0.5908\n",
      "Epoch 44/50\n",
      "145/145 - 0s - loss: 0.4656 - accuracy: 0.8282 - val_loss: 1.1153 - val_accuracy: 0.5875\n",
      "Epoch 45/50\n",
      "145/145 - 0s - loss: 0.4615 - accuracy: 0.8310 - val_loss: 1.1200 - val_accuracy: 0.5849\n",
      "Epoch 46/50\n",
      "145/145 - 0s - loss: 0.4453 - accuracy: 0.8395 - val_loss: 1.1381 - val_accuracy: 0.5764\n",
      "Epoch 47/50\n",
      "145/145 - 0s - loss: 0.4333 - accuracy: 0.8473 - val_loss: 1.1504 - val_accuracy: 0.5791\n",
      "Epoch 48/50\n",
      "145/145 - 0s - loss: 0.4231 - accuracy: 0.8477 - val_loss: 1.1650 - val_accuracy: 0.5856\n",
      "Epoch 49/50\n",
      "145/145 - 0s - loss: 0.3987 - accuracy: 0.8642 - val_loss: 1.1725 - val_accuracy: 0.5849\n",
      "Epoch 50/50\n",
      "145/145 - 0s - loss: 0.3898 - accuracy: 0.8657 - val_loss: 1.1845 - val_accuracy: 0.5823\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "history = model.fit(\n",
    "    padded_training, y_train,\n",
    "    epochs= num_epochs,\n",
    "    validation_data = (padded_test, y_test),\n",
    "    verbose=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
